{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6d7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyctcdecode in /usr/local/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /usr/local/lib/python3.6/site-packages (from pyctcdecode) (6.31.6)\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /usr/local/lib/python3.6/site-packages (from pyctcdecode) (2.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /usr/local/lib64/python3.6/site-packages (from pyctcdecode) (1.19.5)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.6/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (21.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install pyctcdecode\n",
    "!pip install https://github.com/kpu/kenlm/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c26d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def lowerjv(s):\n",
    "    return re.sub(\" +\", \" \", re.sub(\"[^a-z \\n]\",\" \", s.lower().replace(\"j\", \"i\").replace(\"v\", \"u\"))).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a571a730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18694697"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(\"nd-latin-lowerjv.txt\").write_text(lowerjv(Path(\"nd-latin.txt\").read_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5080b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then a miracle occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c7f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kenlm-nd-latin.arpa\", \"r\") as read_file, open(\"5gram_correct.arpa\", \"w\") as write_file:\n",
    "  has_added_eos = False\n",
    "  for line in read_file:\n",
    "    if not has_added_eos and \"ngram 1=\" in line:\n",
    "      count=line.strip().split(\"=\")[-1]\n",
    "      write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n",
    "    elif not has_added_eos and \"<s>\" in line:\n",
    "      write_file.write(line)\n",
    "      write_file.write(line.replace(\"<s>\", \"</s>\"))\n",
    "      has_added_eos = True\n",
    "    else:\n",
    "      write_file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6ba007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"lsb/wav2vec2-base-pemlsb-la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69459ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f2772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n"
     ]
    }
   ],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "import kenlm\n",
    "\n",
    "decoder = build_ctcdecoder(\n",
    "    labels=list(sorted_vocab_dict.keys()),\n",
    "    kenlm_model_path=\"5gram_correct.arpa\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f1dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ProcessorWithLM\n",
    "\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d29c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uiuamus mea lesbia atque amemus rumoresque senum se ueriorum omnes unius ae stimemus assis']\n",
      "['arma uirumque cano troiae qui primus ab oris']\n",
      "['gloriabuntur']\n",
      "['conspirauerunt']\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"lsb/wav2vec2-base-pemlsb-la\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "for f in [\"./vivamus.mp3\", \"./vae11.mp3\", \"./poetaexmachina-mp3-recitations/mp3/1100000\", \"./poetaexmachina-mp3-recitations/mp3/1010000\"]:\n",
    "    soundfile = torchaudio.transforms.Resample(22050, 16000)(torchaudio.load(f, format=\"mp3\")[0]).numpy()\n",
    "    soundfile_input_values = processor_with_lm(soundfile, sampling_rate=16000)['input_values'][0][0]\n",
    "    logits = model(torch.tensor([soundfile_input_values])).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    print(processor.batch_decode(pred_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "738af123",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_with_lm.save_pretrained(\"wav2vec2-base-pemlsb-la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba0bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "repo = Repository(local_dir=\"wav2vec2-base-pemlsb-la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f30f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['language_model/5gram_correct.arpa']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e222d63098049608620a9a903da0f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file language_model/5gram_correct.arpa:   0%|          | 32.0k/408M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/lsb/wav2vec2-base-pemlsb-la\n",
      "   66874a0..3e1c71b  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/lsb/wav2vec2-base-pemlsb-la/commit/3e1c71baad1be8cb63d758dda7fc3d901fa7be6f'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.push_to_hub(commit_message=\"Upload lm-boosted decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95969b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
